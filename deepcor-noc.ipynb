{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f81a97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e00f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"/home/hansika/gem5/gem5/scripts/numpy_data_test/64_nodes/X/2.npy\",  allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca51c86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76608.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size/900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249b1ec2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e357abe7fdbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.count_nonzero(data == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd79ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, file_index):\n",
    "        self.data_dir = data_dir\n",
    "        self.file_index = file_index\n",
    "        y = np.load(self.data_dir + \"Y/\" + str(self.file_index) + \".npy\", allow_pickle=True)\n",
    "        self.y = torch.from_numpy(y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = np.load(self.data_dir + \"X/\" + str(self.file_index) + \".npy\", allow_pickle=True, mmap_mode='r')\n",
    "        x = torch.from_numpy(x)\n",
    "        return [x[index], self.y[index]]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27ae120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = MyDataset(\"/home/hansika/gem5/gem5/scripts/numpy_data/64_nodes/\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "036d4498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6e464fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set,data_set_1 = torch.utils.data.random_split(data_set, [100, 399068])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad7fda6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[160,   8,   1,   1,   1,   2,  25,  47,  24,  44,  11,  13,  12,  19,\n",
       "           10,   1,   1,   1,   2,  67,  65, 121,  52, 187,  81, 126,  16,  27,\n",
       "            1,   1,   1,   2,  21, 112, 238, 127,   1,   1,   1,   2,   1,   1,\n",
       "            1,   1,   1,  48,  29,   5,   1,   1,   1,   2,  11,   1,   1,   1,\n",
       "            2,   5,  60, 260, 100,   1,   1,   1,   2, 106, 113,  88,   1,   1,\n",
       "            1,   2, 216,  23,   1,   1,   1,   2, 490,  64,  55,   1,   1,   1,\n",
       "            2,  38,   1,   1,   1,   2,  87,  60,   1,   1,   1,   2, 163, 144,\n",
       "           45,   1,   1,   1,   2, 147,  59, 212,  43,   1,   1,   1,   2,  77,\n",
       "          131,   1,   1,   1,   2,  91,  13, 146,  73,   1,   1,   1,   2, 227,\n",
       "           95,   1,   1,   1,   2,  37,   1,   1,   1,   2,  47, 169,   1,   1,\n",
       "            1,   2,  74,  44, 478,   1,   1,   1,   1,   2, 162,   1,   1,   1,\n",
       "            2,  73,   1,   1,   1,   2,  47,  56, 106,   1,   1,   1,   2,  22,\n",
       "           63,   1,   1,   1,   2,   7,   1,   1,   1,   2,  93,  59, 439,   3,\n",
       "          235,   1,  37,  38,   1,   1,   1,   1,   1, 204, 293,   1,   1,   1,\n",
       "            2,  70,   1,   1,   1,   1,   1,   1,   1,   1,   1,  82, 443,  18,\n",
       "            1,   1,   1,   2, 469, 117,   1,   1,   1,   2, 360,  12,  33,  10,\n",
       "          109,  13,   1,   1,   1,   2, 143, 321, 164,   1,   1,   1,   2,  11,\n",
       "           48,   1,   1,   1,   2,  59,  27,  19,  63,   1,   1,   1,   2,  69,\n",
       "          188, 106,   1,   1,   1,   2,  12,  80,   1,   1,   1,   2,  83,  79,\n",
       "          118,   1,   1,   1,   2,  37, 263,   1,   1,   1,   2,  71,  95,   1,\n",
       "            1,   1,   2,  71,   2, 158,  67, 264, 215,   1,   1,   1,   2, 219,\n",
       "           31,  76,   1,   1,   1,   1,   1,  59,  14,  33,  66,  96,   1,   1,\n",
       "            1,   2,  63,   1,   1,   1,   2,  70,   1,   1,   1,   2,  12,   1,\n",
       "            1,   1,   2, 112,  53,  57, 158,   1,   1,   1,   2,  86, 183,   1,\n",
       "            1,   1,   2,  71,  45, 116, 129,   1,   1,   1,   2, 211,  30,  25,\n",
       "            1,   1,   1,   2,  67,   8,   1,   1,   1,   1,   1, 193,  73,  38,\n",
       "            1,   1,   1,   2,  85, 132,   1,   1,   1,   2,  49,   1,   1,   1,\n",
       "            2,  62,   1,   1,   1,   2, 250,  22,  33,  93,  60,   1,   1,   1,\n",
       "            2,  84,   1,   1,   1,   2,  85,  20,   1,   1,   1,   2,  61,  14,\n",
       "            1,   1,   1,   2, 126,  16,   7,  23,  27,   1,   1,   1,   2,  11,\n",
       "           53,  19,  22,  32, 621,   1,   1,   1,   1,   1,  38,   1,   1,   1,\n",
       "            2,  41,   1,   1,   1,   2,   1,   1,   1,   1,   2,  17,   2,  56,\n",
       "          113,   1],\n",
       "         [ 42, 120,  82,   1,   1,   1,   2,  79,   1,   1,   1,   2,  48, 165,\n",
       "            2,   1,   1,   1,  82,   1,   1,   2,   1,  20,   1,   1,   1,   2,\n",
       "           57, 153,   1,   1,   2,   1,   6, 423,   1,   1,   1,   2,  42, 111,\n",
       "           13,   1,   1,   1,   2,  96,  88,   1,   1,   1,   2,  21,   9,  50,\n",
       "            7,  15,  72,  47,   1,   1,   1,   2,  36,   1,   2,   2,   2, 230,\n",
       "          473,  72, 198,  36,  36,  15,   1,   1,   1,   2,  15,   5,   1, 129,\n",
       "          104,   1,   1,   1,   2, 282,   1,   1,   1,   2,  23,  34,   1,   1,\n",
       "            2,   2,  74,  67,  90,   6,   1,   1,   1,   2,  42, 212, 144, 247,\n",
       "          123, 168,   2,   2,   2,   2, 103,  34, 130,  74,  90,   1,   1,   1,\n",
       "            1,   1,   1,   1,   1,   1,  96,  67, 265, 156,   1,   1,   1,   2,\n",
       "          137,   4,   3,   1,   1,   1, 113,   1,   1,   1,   2,  91,  23,  23,\n",
       "            1,   1,   1,   2,  47, 103,   2,  39,  15,   1,   1,   1,   2,  46,\n",
       "          193,   1,   1,   1,   2,  44,   1,   1,   1,   2, 195,   2,   1,   1,\n",
       "            1,  26, 106, 393,  52, 106,  91,   1,   1,   1,   2, 146,   1,   1,\n",
       "            1,   2,  96,  42,   9,   2,   1,   1,   1, 155,  40, 101,  15,  61,\n",
       "          122,  63,   1,   1,   1,   2,   1,  71, 167,   1,   1,   1,   2,  55,\n",
       "           33,   5,   1,  20,   2,   1,   1,   1, 232,   1,   1,   1,   2,   2,\n",
       "            3, 197,  38,   1,   1,   1,   2,  44,   1,   1,   1,   2,  83,   1,\n",
       "            1,   1,   2,  11, 116,  30,  80,  42, 243, 163,   1,   1,   1,   2,\n",
       "          104,   2,   2,   2,   1,   8,   3,  16,   1,   1,   1,   2,  60,   8,\n",
       "            1,   1,   1,   2, 250, 203,   1,   1,   1,   2,  56,  35,   2,   2,\n",
       "            1,   1, 191,   2,   2,   2,   2,  63,  54,   2,   1,   1,   1, 157,\n",
       "          104, 119, 131,  59,  19,  26,  24,  95, 101, 110,   9,   1,   1,   1,\n",
       "            2, 153,   1,   1,   1,   2,  40, 129,   1,   1,   1,   2, 262, 215,\n",
       "            2,  71, 167,   1,   1,   1,   2,  35, 143, 270,   1,   1,   1,   2,\n",
       "          121,  20,   1,   1,   1,   3, 248,  56, 490,   1,   1,   1,   3, 118,\n",
       "            2,   1,   1,   1, 215, 568,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "            1,  46,  33, 171, 247,   1,   1,   1,   2,  92,  58,   1,   1,   1,\n",
       "            2, 303,  41,  22, 364,   1,   1,   1,   2,  41,   1,   1,   1,   2,\n",
       "           50,   1,   1,   1,   2,  84,   1,   1,   1,   1,   1, 131,  19,  62,\n",
       "          105,   1,   1,   1,   2,  89, 127,   1,   1,   1,   2,   3, 220,  20,\n",
       "          115,   1,   1,   1,   2, 240, 222,  32,   1,   1,   1,   2,  50,   1,\n",
       "            1,   1]]),\n",
       " tensor(0)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b93a83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dataset = []\n",
    "number_of_files = 41\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "for i in range(number_of_files):\n",
    "    list_of_dataset.append(MyDataset(\"/home/hansika/gem5/gem5/scripts/numpy_data/64_nodes/\",i))\n",
    "\n",
    "full_dataset = ConcatDataset(list_of_dataset)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23f69a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-858f4186a916>:12: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448216815/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  x = torch.from_numpy(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[  7,  50,  52,   1,   1,   1,   2,  31,  94,  60,   1,   1,   1,   2,\n",
       "            4,   1,   1,   1,   2, 176, 156,  29,  44, 190,  21,   1,   1,   1,\n",
       "            2,  10,   1,   1,   1,   2,  58,  57,  35,  24,   1,   1,   1,   2,\n",
       "           27,   1,   1,   1,   2,  69,   1,   1,   1,   2,   3,   1,   1,   1,\n",
       "            2,  22,  42,   1,   1,   1,   2,  68,  77,   8,   1,   1,   1,   2,\n",
       "          172,   1,   1,   1,   2,  60,   1,   1,   1,   2,  35,   1,   1,   1,\n",
       "            2,  19,   1,   1,   1,   2, 140,  78, 151, 333, 102,   1,   1,   1,\n",
       "            1,   1,  66,  22,   1,   1,   1,   2,  38,  34, 123,   1,   1,   1,\n",
       "            2,  26, 196,  76,   1,   1,   1,   2,   1,   1,   1,   1,   1,  68,\n",
       "            1,   1,   1,   2,  54,   1,   1,   1,   2,  80,   1,   1,   1,   2,\n",
       "           48,   1,   1,   1,   2,   1,   7, 127,  64,   1,   1,   1,   2, 134,\n",
       "            1,   1,   1,   2,  46,   1,   1,   1,   2,  34, 140,   1,   1,   1,\n",
       "            2,  19,  92,   3, 127,  65, 180,   1,   1,   1,   2,   6,  90,   1,\n",
       "            1,   1,   2,  24, 343,  90,   1,   1,   1,   2,  28, 160, 209, 132,\n",
       "          140,  15,   1,   1,   1,   2, 144,   1,   1,   1,   1,   1,  39,  74,\n",
       "           65,  28, 209, 126, 266,   3,  92, 196,   1,   1,   1,   2, 137,   1,\n",
       "            1,   1,   2,  30,  68,  94,   1,   1,   1,   2,  87,  55, 112, 263,\n",
       "           25, 168,  89,   1,   1,   1,   2, 242, 241,   1,   1,   1,   2,  33,\n",
       "            1,   1,   1,   2,   4,  38,   7,   1,   1,   1,   2,  29,   1,   1,\n",
       "            1,   2,  28,   1,   1,   1,   2, 179,  81,  31,  10,  11,   1,   1,\n",
       "            1,   3,  93,  66,   1,   1,   1,   2,  98,   1,   1,   1,   2,  51,\n",
       "            1,   1,   1,   2, 143,   1,   1,   1,   2,  81,  42,  27,   1,   1,\n",
       "            1,   2,  55,  94,   1,   1,   1,   2, 179,   1,   1,   1,   2,   4,\n",
       "            1,   1,   1,   2, 174,   1,   1,   1,   2,  57, 194, 248,  72,   1,\n",
       "            1,   1,   2,  84,  71, 206,  38, 201,   1,   1,   1,   2,  46, 321,\n",
       "           59,  28,   1,   1,   1,   2,   9, 157,  66,   2,   1,   1,   1,   2,\n",
       "          191,  41,   1,   1,   1,   1,   1,  96,   1,   1,   1,   2, 186,   1,\n",
       "            1,   1,   2, 204,  96,   1,   1,   1,   2,  58, 679, 153,   1,   1,\n",
       "            1,   2, 309,  87,   1,   1,   1,   2,  55,   1,   1,   1,   2, 163,\n",
       "           20, 144,   1,   1,   1,   1,   1,   1,   1,   1,   1,  33,  44,  54,\n",
       "          112,   2, 194,  61,  13,   1,   1,   1,   2,  76,  68,   1,   1,   1,\n",
       "            2,  82,   3, 423, 156,  69, 136, 106,  23,  17,   1,   1,   1,   2,\n",
       "           16,  66],\n",
       "         [ 20, 192,   2,   1,   1,   1,  10, 230, 315,  66,   3,   2,   1,   1,\n",
       "           25,  10, 151, 250,  10, 298,   1,   1,   1,   2,   5, 426,  19,   1,\n",
       "            1,   1,   2,   5,   1,   1,   1,   2, 209,   1,   1,   1,   2,  40,\n",
       "           40,  38, 154,  82,  53,  41, 126,  76, 346,  49,   2,   1,   1,   1,\n",
       "          203,   1,   1,   1,   2,   4, 498,   1,   1,   2,   2, 201,  45,   1,\n",
       "            1,   1,   2,  84,   1,   1,   1,   2, 195,   1,   1,   1,   2,  11,\n",
       "            1,   1,   1,   2, 125,  97,   1,   2,   1,   1,  44, 371,   1,   1,\n",
       "            1,   2,  17,  14,  74, 196,   1,   1,   2,   1, 146,  78,   1,   1,\n",
       "            1,   2,  20,  82, 212,  19,  65,   1,   1,   1,   2, 142,   1,   1,\n",
       "            1,   2,  17, 100,   1,   1,   1,   2,  58, 904,  82,  54,  60,  34,\n",
       "            1,   1,   1,   2,   1, 214, 515, 166, 165,   1,   1,   1,   2, 132,\n",
       "            1,   1,   1,   2,  24,  18,  55,   1,   1,   1,   2,  83,   1,   1,\n",
       "            1,   2,  54,  42,  22,  15,   3, 105,   3, 253,   2,   1,   1,   1,\n",
       "          250,  92,   3,   1,   1,   1,   2,   1,   3,   1,   1,   1,   1,   1,\n",
       "          229,  39,   1,   1,   1,   2,   1, 172,  36,   1,   1,   1,   2,  10,\n",
       "           85,   1,   1,   1,   2,  35,  55,   3,  68,   2,   2,   2,   1,   1,\n",
       "            2,  11,  27,   8, 240,  91,   4, 416,  25,   1,   1,   1,   2, 221,\n",
       "          109,   1,   1,   1,   2,  94,   2,   2,   2,   2,  26,  33,  22, 110,\n",
       "           57,   1,   1,   1,   2, 400, 124,  38, 291, 169,   1,   1,   1,   2,\n",
       "           39, 171,  29,  45,   1,   1,   1,   2, 343,  21,   1,   1,   1,   2,\n",
       "           18,   1,   1,   1,   2,  10, 153,   4,   2,   2,   2,  49,   1,   1,\n",
       "            1,   2,  10,  82, 226,   1,   1,   1,   2,  34,  22,  40,   1,   1,\n",
       "            1,   2, 266, 348,  55,  12,  13,  26,  89, 176,   1,  33,   1,   1,\n",
       "            1,   2, 306, 193,   9,  17,  17, 113,   1,   1,   1,   2,  28,  33,\n",
       "          452,  66,   1,   1,   1,   2,  31,  97,  51, 105,   1,   1,   1,   2,\n",
       "           34,   1,   1,   1,   2,  57,  62,   2,   2,   2,   2,  97, 322,   1,\n",
       "            1,   1,   2, 118,  23,   1,   1,   1,   2,   3, 126,   1,   1,   1,\n",
       "            2,  22, 317, 232,   2,   1,   1,   1,  82,  47,   1,   1,   1,   2,\n",
       "           93,  52,  65,   1,   1,   1,   2,  57,   1,   1,   1,   2, 102,  85,\n",
       "          151, 125, 131,   6,  59, 144,  75,   2,   1,   1,   1,  26,   1,   1,\n",
       "            1,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0]]),\n",
       " tensor(0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171f0994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16257024"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9db7c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.randn(2,450).view(-1,1,2,450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "780df1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = full_dataset[100][0].view(-1,1,2,450)\n",
    "dummy = dummy.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ca89221",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = full_dataset[100][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d5eb1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset[100][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64790e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# W1, W2, K1, K2 are hyper parameters that eventually needed training\n",
    "W1 = 30\n",
    "W2 = 10\n",
    "K1= 2000\n",
    "K2 = 1000\n",
    "\n",
    "#dummy data to try the NN ( 2 arrays of size 450)\n",
    "# dummy = torch.randn(2,450).view(-1,1,2,450)\n",
    "\n",
    "# represents the whole CNN\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.conv1 = nn.Conv2d(1, K1, (2,W1), stride=(2, 1))\n",
    "        self.pool1 = nn.MaxPool2d((1, 5), stride=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(K1, K2, (1,W2), stride=(1, 1))\n",
    "        self.pool2 = nn.MaxPool2d((1, 5), stride=(1, 1))\n",
    "        \n",
    "        self.fc1 = nn.Linear(1000*404, 3000) # need to automate arriving at this number (1000*254)\n",
    "        self.fc2 = nn.Linear(3000, 800) \n",
    "        self.fc3 = nn.Linear(800,100)\n",
    "        self.fc4 = nn.Linear(100,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1, 1000*404)    \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return torch.sigmoid(x)\n",
    "        \n",
    "\n",
    "    \n",
    "## ------------------------------------testing small net--------------------------- ##\n",
    "\n",
    "# net = SmallNet()\n",
    "# print(net)\n",
    "# print(type(dummy))\n",
    "\n",
    "# output = net.forward(dummy.narrow(2,0,2))\n",
    "# output.shape\n",
    "\n",
    "## --------------------------------end testing small net----------------------------- ##\n",
    "\n",
    "## ---------------------------------------- testing net ----------------------------- ##\n",
    "\n",
    "# net = Net()\n",
    "# print(net)\n",
    "\n",
    "# output = net.forward(dummy)\n",
    "# output.shape\n",
    "\n",
    "## -------------------------------end testing net------------------------------------ ##\n",
    "\n",
    "\n",
    "\n",
    "# ------------------- Training the CNN ------------------------------------- ##\n",
    "# For now this code is only to show the structure, I need to add data preparation and modify code accordingly.\n",
    "\n",
    "isTraining = True\n",
    "if isTraining:\n",
    "   \n",
    "    BATCH_SIZE = 10\n",
    "    EPOCHS = 1\n",
    "    \n",
    "    # need to use collected data here\n",
    "    trainset = torch.utils.data.DataLoader(data_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "#     testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)\n",
    "\n",
    "    # learning rate of the adam optimizer should be a hyperparameter\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for data in trainset:\n",
    "            X, y = data \n",
    "            net.zero_grad()  \n",
    "            X = X.type(torch.FloatTensor)\n",
    "            output = net(X.view(-1,1,2,450))\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "            loss = loss(output, y)\n",
    "            loss.backward() \n",
    "            optimizer.step()  \n",
    "        print(loss)  \n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testset:\n",
    "            X, y = data\n",
    "            output = net(X.view(-1,784))\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "    print(\"Accuracy: \", round(correct/total, 3))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11a22d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7150]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
